{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose / Pivot table Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.set_index('Material Name', inplace=True)\n",
    "\n",
    "trans = df.transpose()\n",
    "\n",
    "trans.reset_index(inplace=True)\n",
    "\n",
    "trans = trans[cols]\n",
    "\n",
    "# One way to do it, for now it can not remain same order easily.\n",
    "trans.melt(id_vars=[\"index\"], ignore_index = False).to_excel('../output/hope.xlsx')\n",
    "\n",
    "# Another way but preverse order.\n",
    "result= trans.set_index([\"index\"]).stack()\n",
    "# Or\n",
    "result = df.pivot(index=[\"some cols\"], columns=\"cols contain values to set name of columns\", values=\"cols that want to get values from\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['columns name'] = pd.to_datetime(df['columns name']], format=\"%d/%m/%Y\", yearfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "df = pd.read_excel('Byun/take_in.xlsx', header=10)\n",
    "\n",
    "sql_engine = create_engine(\n",
    "        'mysql+pymysql://admin:password@ip/scheme', pool_recycle=3600\n",
    "    )\n",
    "take_in.to_sql('table', sql_engine,\n",
    "              if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/bom'\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "dfs = [pd.read_excel(x, header=0, usecols=['Unnamed: 0', 'Plant', 'Entry Date', 'Material', 'Location',\n",
    "       'Stock Type', 'Movement Type', 'Posting Date', 'Unit', 'Quantity',\n",
    "       'Material Document No', 'Provide', 'Reference', 'Unnamed: 13',\n",
    "       'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Previous Stock',\n",
    "       'Entry User']) for x in file_names]\n",
    "def loc_df(df):\n",
    "    lst = [x[0] for x in df['Movement Type'].str.split()]\n",
    "    df['movement type check'] = lst\n",
    "    df = df.loc[df['movement type check'].isin(['101','102','103'])]\n",
    "    return df\n",
    "\n",
    "dfs = [loc_df(df) for df in dfs]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "result.columns\n",
    "result = result[['Material', 'Unit', 'Movement Type', 'Quantity', 'Reference']]\n",
    "end = result.pivot_table(index=['Material', 'Unit'], columns=['Reference'], aggfunc=np.sum)\n",
    "end.to_excel('../output/GIANGALO.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat all sheets in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dfs = pd.read_excel('../data/huy_data/TK 1571-2021 NGUYET GOI CHI THUY (1).xlsx', sheet_name=None, header=5,\n",
    "    #    usecols=['TT', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'USD',\n",
    "    #    'Số lượng', 'Số lượng.1', 'Số lượng.2', 'Số lượng.3']\n",
    ")\n",
    "# for name, df in dfs.items():\n",
    "#     print(df.columns)\n",
    "\n",
    "# def loc_df(df):\n",
    "#     df = df.loc[~(pd.isna(df['Unnamed: 3']))]\n",
    "#     return df\n",
    "dfs = list(dfs.values())\n",
    "# dfs = [loc_df(df) for df in dfs]\n",
    "result = pd.concat(dfs)\n",
    "result.to_excel('../output/TK 1571-2021 NGUYET GOI CHI THUY.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat BOM in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/huy_data/HĐ 2021'\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "\n",
    "dfs = [pd.read_excel(x, header=10\n",
    "       ) for x in file_names]\n",
    "# for x in dfs:\n",
    "#     print(x.columns)\n",
    "\n",
    "def loc_df(df):\n",
    "    df = df.loc[~pd.isna(df['(5)'])]\n",
    "    return df\n",
    "\n",
    "dfs = [loc_df(df) for df in dfs]\n",
    "result = pd.concat(dfs)\n",
    "result.ffill(inplace=True)\n",
    "# result.to_excel('../output/HĐ 2021.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.set_index(['(1)','(2)', '(3)','(4)']).stack().to_excel('../output/HĐ 2021.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/GIANG'\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "dfs = [pd.read_excel(x, header=1, \n",
    "            # usecols=['Unnamed: 0', 'Plant', 'Entry Date', 'Material', 'Location',\n",
    "            # 'Stock Type', 'Movement Type', 'Posting Date', 'Unit', 'Quantity',\n",
    "            # 'Material Document No', 'Provide', 'Reference', 'Unnamed: 13',\n",
    "            # 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Previous Stock',\n",
    "            # 'Entry User']\n",
    "            ) \n",
    "            for x in file_names\n",
    "       ]\n",
    "# def loc_df(df):\n",
    "#     lst = [x[0] for x in df['Movement Type'].str.split()]\n",
    "#     df['movement type check'] = lst\n",
    "#     df = df.loc[df['movement type check'].isin(['101','102','103'])]\n",
    "#     return df\n",
    "\n",
    "# dfs = [loc_df(df) for df in dfs]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "result.to_excel('../output/GIANGALO.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "\n",
    "# df = pd.read_excel('../data/COSTING BOM T1-12.xlsx', header=5)\n",
    "\n",
    "dfs = pd.read_excel('../data/COSTING BOM T1-12.xlsx', sheet_name=None, header=5,)\n",
    "\n",
    "def loc_df(df):\n",
    "    columns = df.columns\n",
    "    columns = [column for column in columns if not str(column).startswith('Unnamed')]\n",
    "    df = df[columns]\n",
    "    df = df.loc[~pd.isna(df['Mã']) & ~(df['Mã'] == 'Đơn giá NVL') & ~(df['Mã'] == 0)]\n",
    "    result= df.set_index([\"Mã\"]).stack()\n",
    "\n",
    "    result = pd.DataFrame(result)\n",
    "    result.reset_index(inplace=True)\n",
    "    result = result.drop(result[result[0] == 0].index)\n",
    "    return result\n",
    "\n",
    "dfs = [loc_df(df) for df in dfs.values()]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "with ExcelWriter('../output/end.xlsx') as writer:\n",
    "    for n, df in enumerate(dfs, start=1):\n",
    "        df.rename(columns={\n",
    "            'Mã': 'TP',\n",
    "            'level_1': 'NVL',\n",
    "            0: 'VALUE'\n",
    "        }, inplace=True)\n",
    "        df.to_excel(writer,'sheet %s' % n, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/BOM INZI.xlsb')\n",
    "\n",
    "df = df.loc[~pd.isna(df['Semi']) & ~pd.isna(df['Technical BOM'])]\n",
    "df = df[['Level.', 'Product', 'Semi', 'RM', 'Name', 'Unit','Technical BOM']]\n",
    "df['Level.'] = [x.split('.')[-1] for x in df['Level.']]\n",
    "df['Level.'] = df['Level.'].astype(int)\n",
    "\n",
    "# rats = []\n",
    "# previous_level = 1\n",
    "# ratio = [1] * (len(df['Level.'].unique()) + 1)\n",
    "\n",
    "# for row in zip(df['Level.'], df['Technical BOM']):\n",
    "#     if row[0] > 1:\n",
    "#         if row[0] > previous_level:\n",
    "#             ratio[row[0]] = ratio[row[0] - 1] * previous_ratio\n",
    "    \n",
    "#     rats.append(ratio[row[0]])\n",
    "\n",
    "#     previous_ratio = row[1]\n",
    "#     previous_level = row[0]\n",
    "\n",
    "# df['ratio'] = rats\n",
    "# df['BOM'] = df['Technical BOM'] * df['ratio']\n",
    "\n",
    "\n",
    "\n",
    "indexs = []\n",
    "current_level = 1\n",
    "for count, x in enumerate(df['Level.'], start=-1):\n",
    "    if x > current_level:\n",
    "        indexs.append(count)\n",
    "    current_level = x\n",
    "\n",
    "df = df.drop(df.index[indexs])\n",
    "\n",
    "df.to_excel('../output/ENDING.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/BCQT2021.BOM.xlsx', header=9)\n",
    "df = df.groupby(['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Mã', 'Tên',\n",
    "       'Đơn vị tính']).sum()\n",
    "df.to_excel('../output/bcqt.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/(03.04.2022)_MEGAELEC_16 FORM_PROCESSING.xlsb', header=10)\n",
    "df = df.groupby(['(1)', '(2)', '(3)', '(4)', '(5)', '(6)', '(7)']).sum()\n",
    "df.reset_index().to_excel('../output/GIANGx.xlsx')\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def Insert_row(row_number, df, row_value):\n",
    "    # Starting value of upper half\n",
    "    start_upper = 0\n",
    "  \n",
    "    # End value of upper half\n",
    "    end_upper = row_number\n",
    "  \n",
    "    # Start value of lower half\n",
    "    start_lower = row_number\n",
    "  \n",
    "    # End value of lower half\n",
    "    end_lower = df.shape[0]\n",
    "  \n",
    "    # Create a list of upper_half index\n",
    "    upper_half = [*range(start_upper, end_upper, 1)]\n",
    "  \n",
    "    # Create a list of lower_half index\n",
    "    lower_half = [*range(start_lower, end_lower, 1)]\n",
    "  \n",
    "    # Increment the value of lower half by 1\n",
    "    lower_half = [x.__add__(1) for x in lower_half]\n",
    "  \n",
    "    # Combine the two lists\n",
    "    index_ = upper_half + lower_half\n",
    "  \n",
    "    # Update the index of the dataframe\n",
    "    df.index = index_\n",
    "  \n",
    "    # Insert a row at the end\n",
    "    df.loc[row_number] = row_value\n",
    "   \n",
    "    # Sort the index labels\n",
    "    df = df.sort_index()\n",
    "  \n",
    "    # return the dataframe\n",
    "    return df\n",
    "  \n",
    "\n",
    "\n",
    "df = pd.read_excel('../data/(01.04.2022)_MEGAELEC_16 FORM_PROCESSING copy (1).xlsb', header=11)\n",
    "k = 0\n",
    "\n",
    "df = df.loc[df['(5)'] != 'EX-04-00017']\n",
    "current = '00-000-2276-REV-E-MG'\n",
    "for count, x in enumerate(df['(2)']):\n",
    "    if x != current:\n",
    "        for _ in range(11):\n",
    "            df = Insert_row(count + k, df, pd.Series())\n",
    "        k += 11\n",
    "    current = x\n",
    "    \n",
    "\n",
    "df.to_excel('../output/aaaaa.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/(04.04.2022)_MEGAELEC_SUMMARIZE REPORT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ECUS CODE', 'ACC CODE', 'DECRIPTION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_step_1(row):\n",
    "    string = row['DECRIPTION']\n",
    "    string = string.split()\n",
    "    for x in string:\n",
    "        if len(x.split('-')) > 1:\n",
    "            return x.split(',')[0]\n",
    "    return row['DECRIPTION']\n",
    "\n",
    "def get_code_step_2(row):\n",
    "    string = row['CODE']\n",
    "    if len(string.split()) > 1:\n",
    "        return string.split(',')[0].split()[-1]\n",
    "    return row['CODE']\n",
    "\n",
    "df['CODE'] = df.apply(lambda row: get_code_step_1(row), axis=1)\n",
    "df['CODE'] = df.apply(lambda row: get_code_step_2(row), axis=1)\n",
    "\n",
    "df_obj = df.select_dtypes(['object'])\n",
    "\n",
    "df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "df.to_excel('../output/result.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bom = pd.read_excel('../data/bom.xlsx')\n",
    "iob = pd.read_excel('../data/iob.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bom.columns)\n",
    "print(iob.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(iob, bom, how='inner', left_on=['balance__code', 'balance__unit'], right_on=['bom_belong__code', 'bom_belong__unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "'''  MATL '''\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/2021'\n",
    "tp_url = '../data/DAILY PRODUCTION 2021.xlsx'\n",
    "sheet_name = '2021'\n",
    "output_url = '../output/2021_full.xlsx'\n",
    "\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "dfs = [pd.read_excel(x, header=0, converters={'Article No': str, 'Material Code': str, 'File No': str}, usecols=['Article No', 'Material Code', 'Unit', 'D/O Unit Stock Qty']) for x in file_names]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "df = result\n",
    "nvl = df.groupby(['Article No', 'Material Code', 'Unit'], sort=False).agg(\n",
    "            {'D/O Unit Stock Qty': 'sum'})\n",
    "nvl.reset_index(inplace=True)\n",
    "tp = pd.read_excel(tp_url, sheet_name=sheet_name, converters={'Article Code': str}, usecols=['Article Code', 'TOTAL OUTPUT Qty.'])\n",
    "sx = tp.groupby(['Article Code'], sort=False).agg(\n",
    "            {'TOTAL OUTPUT Qty.': 'sum'})\n",
    "sx.reset_index(inplace=True)\n",
    "nvl.rename(columns={'Article No': 'Article Code'}, inplace=True)\n",
    "\n",
    "\n",
    "bom = pd.merge(nvl, sx, how=\"left\", on='Article Code', sort=False,\n",
    "                          indicator=False, validate=None)\n",
    "bom['BOM'] = bom['D/O Unit Stock Qty'] / bom['TOTAL OUTPUT Qty.']\n",
    "# bom.loc[~pd.isna(bom['TOTAL OUTPUT Qty.'])].to_excel('../output/2019.xlsx')\n",
    "bom.to_excel(output_url)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "'''  MATL '''\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/bom btp'\n",
    "\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "dfs = [pd.read_excel(x, header=0, converters={'Material': str, 'Component': str}) for x in file_names]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "result.to_excel('../output/semi.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = pd.read_excel('../data/2022-05-05_BOM_2.xlsx', converters={'Code': str, 'Material Code': str})\n",
    "name_df = name_df[['Code', 'ECUS']].drop_duplicates()\n",
    "bom = pd.read_excel('../data/Bom.xlsx', converters={'Code': str, 'Material Code': str})\n",
    "result = pd.merge(bom, name_df, on='Code', how='left')\n",
    "result.sort_values(['Code', 'ECUS'], ascending=[True, True], inplace=True)\n",
    "result.to_excel('../output/sort.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = pd.read_excel('../data/Truy van ket qua san xuat 01012022 31032022.xlsx', header=2)\n",
    "nvl = pd.read_excel('../data/Tinh hinh nhap NVL vao sx 01012022 31032022 - Copy.xlsx')\n",
    "\n",
    "sx.rename(columns={'Đơn vị': 'Product Unit', 'Mã hàng': 'Product'}, inplace=True)\n",
    "nvl.rename(columns={'Đơn vị': 'Material Unit', 'Mã số NPL': 'Material'}, inplace=True)\n",
    "\n",
    "sx = sx[['Product', 'LotNo', 'Số lượng hàng đạt', 'Product Unit']]\n",
    "nvl = nvl[['Material', 'LotNo', 'Số lượng nhập', 'Material Unit']]\n",
    "\n",
    "sx.drop_duplicates(inplace=True)\n",
    "result = pd.merge(sx, nvl, how=\"inner\", on='LotNo', sort=False,\n",
    "                  indicator=False, validate=None)\n",
    "\n",
    "pro_qty = result[['Product', 'LotNo', 'Số lượng hàng đạt']]\n",
    "pro_qty.drop_duplicates(inplace=True)\n",
    "pro_qty = pro_qty.groupby('Product').agg(\n",
    "    {'Số lượng hàng đạt': 'sum'})\n",
    "pro_qty.reset_index(inplace=True)\n",
    "result = result.groupby(['Product', 'Product Unit', 'Material', 'Material Unit']).agg(\n",
    "    {'Số lượng nhập': 'sum'})\n",
    "result.reset_index(inplace=True)\n",
    "result = pd.merge(result, pro_qty, how=\"left\", on=['Product'], sort=False,\n",
    "                  indicator=False, validate=None)\n",
    "result['BOM'] = result['Số lượng nhập'] / result['Số lượng hàng đạt']\n",
    "result.to_excel('../output/bom.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = df.groupby(['(2)', '(4)', '(5)', '(7)', '(9)']).agg(\n",
    "    {'(8)': 'sum'})\n",
    "result.reset_index(inplace=True)\n",
    "result['(9)'] = result['(9)'].str.replace('a', '')\n",
    "result.to_excel('../output/bom.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../output/bom.xlsx')\n",
    "\n",
    "df[' Mã NVL'] = df[' Mã NVL'].str.upper()\n",
    "df['Đơn vị tính.1'] = df['Đơn vị tính.1'].str.strip()\n",
    "\n",
    "df[' Mã NVL'] = df[' Mã NVL'].str.upper()\n",
    "df['Đơn vị tính.1'] = df['Đơn vị tính.1'].str.strip()\n",
    "\n",
    "df = df[[' Mã NVL', 'Đơn vị tính.1']]\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df = df.loc[df.duplicated(subset=' Mã NVL', keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('../output/dup.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bare = pd.read_excel('../data/merge_pros.xlsx', sheet_name='bare')\n",
    "df1 = pd.read_excel('../data/merge_pros.xlsx', sheet_name='first', converters={'cd_import': str})\n",
    "df2 = pd.read_excel('../data/merge_pros.xlsx', sheet_name='second', converters={'cd_export': str})\n",
    "\n",
    "result = pd.merge(df1, df2, how=\"outer\", on=['code', 'registered_date'], sort=False, indicator=False, validate=None).sort_values(['code', 'registered_date'])\n",
    "\n",
    "count_1 = df1.groupby(['code', 'registered_date']).aggregate({'cd_import': 'count'}).reset_index()\n",
    "count_2 = df2.groupby(['code', 'registered_date']).aggregate({'cd_export': 'count'}).reset_index()\n",
    "count = pd.merge(count_1, count_2, how=\"outer\", on=['code', 'registered_date'], sort=False, indicator=False, validate=None).sort_values(['code', 'registered_date'])\n",
    "\n",
    "count = count.fillna(1)\n",
    "count['total'] = count['cd_import'] * count['cd_export']\n",
    "\n",
    "count['cd_import'] = count['cd_import'].astype(int)\n",
    "count['cd_export'] = count['cd_export'].astype(int)\n",
    "count['total'] = count['total'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_delete = list()\n",
    "\n",
    "i = 0\n",
    "for row in zip(count['cd_import'], count['cd_export'], count['total']):\n",
    "    if row[0] > 1 and row[1] > 1:\n",
    "        if row[0] >= row[1]:\n",
    "            k = row[1] - 1\n",
    "        else:\n",
    "            k = row[0] - 1\n",
    "        l = i + 1\n",
    "        for _ in range(k):\n",
    "            indexes_to_delete += range(l, l + row[1])\n",
    "            l += row[1]\n",
    "    i += row[2]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/BOM.CT.xlsx', sheet_name='Sheet1', header=2)\n",
    "\n",
    "df['(2)'] = df['(2)'].str.upper()\n",
    "df['(4)'] = df['(4)'].str.upper()\n",
    "df['(5)'] = df['(5)'].str.upper()\n",
    "df['(7)'] = df['(7)'].str.upper()\n",
    "\n",
    "df['(2)'] = df['(2)'].str.strip()\n",
    "df['(4)'] = df['(4)'].str.strip()\n",
    "df['(5)'] = df['(5)'].str.strip()\n",
    "df['(7)'] = df['(7)'].str.strip()\n",
    "\n",
    "result = df.groupby(['(2)', '(4)', '(5)', '(7)']).agg(\n",
    "    {'(8)': 'sum'})\n",
    "result.reset_index(inplace=True)\n",
    "name_tp = df[['(2)', '(3)']]\n",
    "name_tp.drop_duplicates(inplace=True, keep='first', subset='(2)')\n",
    "name_nvl = df[['(5)', '(6)']]\n",
    "name_nvl.drop_duplicates(inplace=True, keep='first', subset='(5)')\n",
    "result = pd.merge(result, name_tp, on='(2)', how='left')\n",
    "result = pd.merge(result, name_nvl, on='(5)', how='left')\n",
    "result.to_excel('../output/bom.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_df = pd.read_excel('../data/BOM_TC.xlsx', sheet_name='Sheet1', header=2)\n",
    "semi_1 = pd.read_excel('../data/2000185.XLSX', sheet_name='ST-0,075x7,212')\n",
    "semi_2 = pd.read_excel('../data/2000185.XLSX', sheet_name='ST-0,075x5,744')\n",
    "\n",
    "bom_df['(5)'] = bom_df['(5)'].str.upper()\n",
    "semi_1['Products code'] = semi_1['Products code'].str.upper()\n",
    "semi_2['Products code'] = semi_2['Products code'].str.upper()\n",
    "semi_1 = semi_1[['Products code', 'Product unit', 'Ecus (Vlookup)','Component Description', 'Qty', 'Unit']]\n",
    "semi_2 = semi_2[['Products code', 'Product unit', 'Ecus (Vlookup)','Component Description', 'Qty', 'Unit']]\n",
    "\n",
    "result = pd.merge(bom_df, semi_1, left_on=['(5)', '(7)'], right_on=['Products code', 'Product unit'], how='left' ,sort=False, indicator=False, validate=None)\n",
    "result = pd.merge(result, semi_2, left_on=['(5)', '(7)'], right_on=['Products code', 'Product unit'], how='left' ,sort=False, indicator=False, validate=None)\n",
    "\n",
    "def replace_material(row):\n",
    "    if not pd.isna(row['Ecus (Vlookup)_x']):\n",
    "        return row['Ecus (Vlookup)_x']\n",
    "    if not pd.isna(row['Ecus (Vlookup)_y']):\n",
    "        return row['Ecus (Vlookup)_y']\n",
    "    return row['(5)']\n",
    "\n",
    "def replace_name(row):\n",
    "    if not pd.isna(row['Component Description_x']):\n",
    "        return row['Component Description_x']\n",
    "    if not pd.isna(row['Component Description_y']):\n",
    "        return row['Component Description_y']\n",
    "    return row['(6)']\n",
    "\n",
    "def replace_unit(row):\n",
    "    if not pd.isna(row['Unit_x']):\n",
    "        return row['Unit_x']\n",
    "    if not pd.isna(row['Unit_y']):\n",
    "        return row['Unit_y']\n",
    "    return row['(7)']\n",
    "\n",
    "def replace_bom(row):\n",
    "    if not pd.isna(row['Qty_x']):\n",
    "        return row['Qty_x'] * row['(8)']\n",
    "    if not pd.isna(row['Qty_y']):\n",
    "        return row['Qty_y'] * row['(8)']\n",
    "    return row['(8)']\n",
    "\n",
    "\n",
    "result['(5)'] = result.apply(lambda row: replace_material(row), axis=1)\n",
    "result['(6)'] = result.apply(lambda row: replace_name(row), axis=1)\n",
    "result['(7)'] = result.apply(lambda row: replace_unit(row), axis=1)\n",
    "result['(8)'] = result.apply(lambda row: replace_bom(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result\n",
    "\n",
    "df['(2)'] = df['(2)'].str.upper()\n",
    "df['(4)'] = df['(4)'].str.upper()\n",
    "df['(5)'] = df['(5)'].str.upper()\n",
    "df['(7)'] = df['(7)'].str.upper()\n",
    "\n",
    "df['(2)'] = df['(2)'].str.strip()\n",
    "df['(4)'] = df['(4)'].str.strip()\n",
    "df['(5)'] = df['(5)'].str.strip()\n",
    "df['(7)'] = df['(7)'].str.strip()\n",
    "\n",
    "result = df.groupby(['(2)', '(4)', '(5)', '(7)']).agg(\n",
    "    {'(8)': 'sum'})\n",
    "result.reset_index(inplace=True)\n",
    "name_tp = df[['(2)', '(3)']]\n",
    "name_tp.drop_duplicates(inplace=True, keep='first', subset='(2)')\n",
    "name_nvl = df[['(5)', '(6)']]\n",
    "name_nvl.drop_duplicates(inplace=True, keep='first', subset='(5)')\n",
    "result = pd.merge(result, name_tp, on='(2)', how='left')\n",
    "result = pd.merge(result, name_nvl, on='(5)', how='left')\n",
    "result.to_excel('../output/boms.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/abc.xlsx', converters={'cd_import': str, 'cd_export': str})\n",
    "\n",
    "df[\"import_quantity\"] = pd.to_numeric(df[\"import_quantity\"])\n",
    "df[\"export_quantity\"] = pd.to_numeric(df[\"export_quantity\"])\n",
    "df[\"begin\"] = 0\n",
    "df['temp_import_quantity'] = df.groupby('code')['import_quantity'].cumsum()\n",
    "df['temp_export_quantity'] = df.groupby('code')['export_quantity'].cumsum()\n",
    "df['end'] = df['begin'] + df['temp_import_quantity'] - df['temp_export_quantity']\n",
    "df['begin'] = df['end'] + df['export_quantity'] - df['import_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_to_str(row):\n",
    "    try:\n",
    "        return row['Ngày ĐK'].strftime('%d/%m/%Y')\n",
    "    except:\n",
    "        return row['Ngày ĐK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bom = pd.read_excel('../data/bom.xlsx')\n",
    "ecus = pd.read_excel('../data/ecus.xlsx', converters={'Số TK': str})\n",
    "\n",
    "ecus['Ngày ĐK'] = ecus.apply(lambda row: datetime_to_str(row), axis=1)\n",
    "ecus['Ngày ĐK'] = pd.to_datetime(ecus['Ngày ĐK'], dayfirst=True)\n",
    "\n",
    "name_df = ecus[['Mã NPL/SP', 'Tên hàng', 'Đơn vị tính']]\n",
    "name_df.drop_duplicates(inplace=True, keep='first', subset=['Mã NPL/SP'])\n",
    "\n",
    "import_df = ecus.loc[(ecus['Mã loại hình'] == 'A12') & (~pd.isna(ecus['Mã NPL/SP']))]\n",
    "export_df = ecus.loc[(ecus['Mã loại hình'] == 'E62') & (~pd.isna(ecus['Mã NPL/SP']))]\n",
    "\n",
    "\n",
    "import_df = import_df[['Số TK', 'Ngày ĐK', 'Tổng số lượng', 'Tên hàng', 'Mã NPL/SP', 'Đơn vị tính', 'Tổng trị giá', 'Thuế suất XNK']]\n",
    "export_df = export_df[['Số TK', 'Ngày ĐK', 'Tổng số lượng', 'Tên hàng', 'Mã NPL/SP', 'Đơn vị tính']]\n",
    "export_bom_df = pd.merge(export_df, bom, how='left', left_on='Mã NPL/SP', right_on='product_code')\n",
    "\n",
    "import_df.rename(columns={\n",
    "    'Số TK': 'CD IMPORT',\n",
    "    'Mã NPL/SP': 'NVL',\n",
    "    'Tên hàng': 'NVL NAME',\n",
    "    'Đơn vị tính': 'NVL UNIT',\n",
    "    'Tổng số lượng': 'NVL QTY'\n",
    "}, inplace=True)\n",
    "export_bom_df.rename(columns={\n",
    "    'Số TK': 'CD EXPORT',\n",
    "    'Mã NPL/SP': 'TP',\n",
    "    'Tên hàng': 'TP NAME',\n",
    "    'Đơn vị tính': 'TP UNIT',\n",
    "    'Tổng số lượng': 'TP QTY',\n",
    "    'code': 'NVL'\n",
    "}, inplace=True)\n",
    "\n",
    "export_bom_df['TP QTY'] = export_bom_df['TP QTY'] * export_bom_df['bom_value']\n",
    "\n",
    "df = pd.merge(import_df, export_bom_df, how=\"outer\", on=['NVL', 'Ngày ĐK'], sort=False, indicator=False, validate=None)\n",
    "df = df.loc[df['NVL'].isin(import_df['NVL'].unique())]\n",
    "df.sort_values(['NVL', 'Ngày ĐK'], inplace=True)\n",
    "\n",
    "count_1 = import_df.groupby(['NVL', 'Ngày ĐK']).aggregate({'CD IMPORT': 'count'}).reset_index()\n",
    "count_2 = export_bom_df.groupby(['NVL', 'Ngày ĐK']).aggregate({'CD EXPORT': 'count'}).reset_index()\n",
    "count_2 = count_2.loc[count_2['NVL'].isin(import_df['NVL'].unique())]\n",
    "count = pd.merge(count_1, count_2, how=\"outer\", on=['NVL', 'Ngày ĐK'], sort=False, indicator=False, validate=None).sort_values(['NVL', 'Ngày ĐK'])\n",
    "count = count.fillna(1)\n",
    "count['total'] = count['CD IMPORT'] * count['CD EXPORT']\n",
    "count['CD IMPORT'] = count['CD IMPORT'].astype(int)\n",
    "count['CD EXPORT'] = count['CD EXPORT'].astype(int)\n",
    "count['total'] = count['total'].astype(int)\n",
    "count = count.loc[count['NVL'].isin(import_df['NVL'].unique())]\n",
    "indexes_to_delete = list()\n",
    "\n",
    "i = 0\n",
    "for row in zip(count['CD IMPORT'], count['CD EXPORT'], count['total']):\n",
    "    if row[0] > 1 and row[1] > 1:\n",
    "        k = row[0] - 1\n",
    "        if row[0] >= row[1]:\n",
    "            k = row[1] - 1\n",
    "        l = i + 1\n",
    "        for _ in range(k):\n",
    "            indexes_to_delete += range(l, l + row[1])\n",
    "            l += row[1]\n",
    "    i += row[2]\n",
    "\n",
    "df = df.drop(indexes_to_delete)\n",
    "\n",
    "# 4 columns to insert\n",
    "import_cd = list()\n",
    "import_qt = list()\n",
    "export_cd = list()\n",
    "export_qty = list()\n",
    "current_import_cd = ''\n",
    "current_export_cd = ''\n",
    "current_code = None\n",
    "current_date = ''\n",
    "current_tp = None\n",
    "for _, row in df.iterrows():\n",
    "    if current_code:\n",
    "        if current_import_cd == row['CD IMPORT'] and current_import_cd:\n",
    "            if current_date == row['Ngày ĐK'] and current_code == row['NVL']:\n",
    "                import_cd.append('')\n",
    "                import_qt.append(0)\n",
    "            else:\n",
    "                import_cd.append(row['CD IMPORT'])\n",
    "                import_qt.append(row['NVL QTY'])\n",
    "        else:\n",
    "            import_cd.append(row['CD IMPORT'])\n",
    "            import_qt.append(row['NVL QTY'])\n",
    "\n",
    "        if current_export_cd == row['CD EXPORT'] and current_export_cd:\n",
    "            if current_date == row['Ngày ĐK'] and current_code == row['NVL'] and current_tp==row['TP']:\n",
    "                export_cd.append('')\n",
    "                export_qty.append(0)\n",
    "            else:\n",
    "                export_cd.append(row['CD EXPORT'])\n",
    "                export_qty.append(row['TP QTY'])\n",
    "        else:\n",
    "            export_cd.append(row['CD EXPORT'])\n",
    "            export_qty.append(row['TP QTY'])\n",
    "    else:\n",
    "        import_cd.append(row['CD IMPORT'])\n",
    "        import_qt.append(row['NVL QTY'])\n",
    "        export_cd.append(row['CD EXPORT'])\n",
    "        export_qty.append(row['TP QTY'])\n",
    "\n",
    "    current_code = row['NVL']\n",
    "    current_date = row['Ngày ĐK']\n",
    "    current_import_cd = row['CD IMPORT']\n",
    "    current_export_cd = row['CD EXPORT']\n",
    "    current_tp = row['TP']\n",
    "\n",
    "\n",
    "df['CD IMPORT'] = import_cd\n",
    "df['CD EXPORT'] = export_cd\n",
    "df['NVL QTY'] = import_qt\n",
    "df['TP QTY'] = export_qty\n",
    "\n",
    "# df.loc[df['NVL'] == '3216-02540-00'].to_excel('../output/wtf.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_first = df.drop_duplicates(subset=['NVL'], keep='first')\n",
    "out_first = out_first.loc[pd.isna(out_first['NVL QTY'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (2381) does not match length of index (2390)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5864/3680973518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[0mbom_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'import_cd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_cds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'export_cd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_cds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nvl_name_x'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnvl_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Projects\\Excel-to-SQL-snippets\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Projects\\Excel-to-SQL-snippets\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32md:\\Projects\\Excel-to-SQL-snippets\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Projects\\Excel-to-SQL-snippets\\env\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (2381) does not match length of index (2390)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../output/prepare_move.xlsx', converters={'import_cd': str, 'export_cd': str})\n",
    "df['export_date'] = df['Ngày ĐK']\n",
    "df = df.loc[~pd.isna(df['import_cd']) | ~pd.isna(df['export_cd'])]\n",
    "df.rename(columns={'Ngày ĐK': 'import_date'}, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "del df['index']\n",
    "\n",
    "export_null = 0\n",
    "import_null = 0\n",
    "\n",
    "nvl_names = []\n",
    "nvl_units = []\n",
    "\n",
    "import_cds = []\n",
    "import_dates = []\n",
    "import_qty = []\n",
    "\n",
    "tax_totals = []\n",
    "tax_rates = []\n",
    "\n",
    "export_cds = []\n",
    "export_dates = []\n",
    "export_qty = []\n",
    "tps = []\n",
    "tp_units = []\n",
    "tp_names = []\n",
    "bom_values = []\n",
    "\n",
    "to_delete = []\n",
    "\n",
    "current_code = None\n",
    "\n",
    "for count, row in df.iterrows():\n",
    "    if not current_code:\n",
    "        if not pd.isna(row['import_cd']):\n",
    "            import_cds.append(row['import_cd'])\n",
    "            nvl_names.append(row['nvl_name_x'])\n",
    "            nvl_units.append(row['nvl_unit_x'])\n",
    "            import_dates.append(row['import_date'])\n",
    "            import_qty.append(row['import_qty'])\n",
    "            tax_totals.append(row['Tổng trị giá'])\n",
    "            tax_rates.append(row['Thuế suất XNK'])\n",
    "        else:\n",
    "            import_null += 1\n",
    "\n",
    "        if not pd.isna(row['export_cd']):\n",
    "            export_cds.append(row['export_cd'])\n",
    "            export_dates.append(row['export_date'])\n",
    "            export_qty.append(row['export_qty'])\n",
    "            tps.append(row['tp_code'])\n",
    "            tp_units.append(row['tp_unit'])\n",
    "            tp_names.append(row['tp_name'])\n",
    "            bom_values.append(row['bom'])\n",
    "\n",
    "        else:\n",
    "            export_null += 1\n",
    "\n",
    "    else:\n",
    "        if current_code == row['nvl_code']:\n",
    "            if not pd.isna(row['import_cd']):\n",
    "                import_cds.append(row['import_cd'])\n",
    "                nvl_names.append(row['nvl_name_x'])\n",
    "                nvl_units.append(row['nvl_unit_x'])\n",
    "                import_dates.append(row['import_date'])\n",
    "                import_qty.append(row['import_qty'])\n",
    "                tax_totals.append(row['Tổng trị giá'])\n",
    "                tax_rates.append(row['Thuế suất XNK'])\n",
    "            else:\n",
    "                import_null += 1\n",
    "\n",
    "            if not pd.isna(row['export_cd']):\n",
    "                export_cds.append(row['export_cd'])\n",
    "                export_dates.append(row['export_date'])\n",
    "                export_qty.append(row['export_qty'])\n",
    "                tps.append(row['tp_code'])\n",
    "                tp_units.append(row['tp_unit'])\n",
    "                tp_names.append(row['tp_name'])\n",
    "                bom_values.append(row['bom'])\n",
    "            else:\n",
    "                export_null += 1\n",
    "    \n",
    "        else:\n",
    "            j = min([import_null, export_null])\n",
    "            to_delete += range(count-j, count)\n",
    "\n",
    "            import_cds += [None] * import_null\n",
    "            nvl_names += [None] * import_null\n",
    "            nvl_units += [None] * import_null\n",
    "            import_dates += [None] * import_null\n",
    "            import_qty += [None] * import_null\n",
    "            tax_totals += [None] * import_null\n",
    "            tax_rates += [None] * import_null\n",
    "\n",
    "            export_cds += [None] * export_null\n",
    "            export_dates += [None] * export_null\n",
    "            export_qty += [None] * export_null\n",
    "            tps += [None] * export_null\n",
    "            tp_units += [None] * export_null\n",
    "            tp_names += [None] * export_null\n",
    "            bom_values += [None] * export_null\n",
    "\n",
    "            import_null = 0\n",
    "            export_null = 0\n",
    "\n",
    "            if pd.isna(row['import_cd']):\n",
    "                import_null = 1\n",
    "            else:\n",
    "                import_cds.append(row['import_cd'])\n",
    "                nvl_names.append(row['nvl_name_x'])\n",
    "                nvl_units.append(row['nvl_unit_x'])\n",
    "                import_dates.append(row['import_date'])\n",
    "                import_qty.append(row['import_qty'])\n",
    "                tax_totals.append(row['Tổng trị giá'])\n",
    "                tax_rates.append(row['Thuế suất XNK'])\n",
    "\n",
    "            if pd.isna(row['export_cd']):\n",
    "                export_null = 1\n",
    "            else:\n",
    "                export_cds.append(row['export_cd'])\n",
    "                export_dates.append(row['export_date'])\n",
    "                export_qty.append(row['export_qty'])\n",
    "                tps.append(row['tp_code'])\n",
    "                tp_units.append(row['tp_unit'])\n",
    "                tp_names.append(row['tp_name'])\n",
    "                bom_values.append(row['bom'])\n",
    "\n",
    "    current_code = row['nvl_code']\n",
    "\n",
    "export_cds.append(None)\n",
    "export_dates.append(None)\n",
    "export_qty.append(None)\n",
    "tps.append(None)\n",
    "tp_units.append(None)\n",
    "tp_names.append(None)\n",
    "bom_values.append(None)\n",
    "\n",
    "df['import_cd'] = import_cds\n",
    "df['export_cd'] = export_cds\n",
    "df['nvl_name_x'] = nvl_names\n",
    "df['nvl_unit_x'] = nvl_units\n",
    "df['import_date'] = import_dates\n",
    "df['import_qty'] = import_qty\n",
    "df['Tổng trị giá'] = tax_totals\n",
    "df['Thuế suất XNK'] = tax_rates\n",
    "df['export_date'] = export_dates\n",
    "df['export_qty'] = export_qty\n",
    "df['tp_code'] = tps\n",
    "df['tp_unit'] = tp_units\n",
    "df['tp_name'] = tp_names\n",
    "df['bom'] = bom_values\n",
    "\n",
    "df = df.drop(to_delete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_code = None\n",
    "\n",
    "current_import_cd = []\n",
    "current_export_cd = []\n",
    "\n",
    "current_import = []\n",
    "current_export = []\n",
    "\n",
    "\n",
    "import_cds = []\n",
    "export_cds = []\n",
    "\n",
    "codes = []\n",
    "dfx = df\n",
    "for count, row in dfx.iterrows():\n",
    "    if not current_code:\n",
    "        current_import_cd.append(row['CD IMPORT'])\n",
    "        current_export_cd.append(row['CD EXPORT'])\n",
    "\n",
    "        current_import.append(row['NVL QTY'])\n",
    "        current_export.append(row['TP QTY'])\n",
    "\n",
    "    else:\n",
    "        if current_code == row['NVL']:\n",
    "            current_import_cd.append(row['CD IMPORT'])\n",
    "            current_export_cd.append(row['CD EXPORT'])\n",
    "            \n",
    "            current_import.append(row['NVL QTY'])\n",
    "            current_export.append(row['TP QTY'])\n",
    "        else:\n",
    "            # GET DICE FOR DEVIDE LIST\n",
    "            k = 0\n",
    "            im = current_import[k]\n",
    "            ex = 0\n",
    "            dice = []\n",
    "            for i in range(len(current_export)):\n",
    "                ex += current_export[i]\n",
    "                if ex >= im:\n",
    "                    dice.append(i)\n",
    "                    k += 1\n",
    "                    if len(current_export) == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        im += current_import[k]\n",
    "\n",
    "\n",
    "            temp_cd = []\n",
    "            l = len(current_import_cd)\n",
    "            if len(dice) > 0:\n",
    "                for i in range(len(dice) - 1):\n",
    "                    temp_cd.append(current_import_cd.pop(0))\n",
    "                    if i > 0:\n",
    "                        n = dice[i] - dice[i-1] - 1\n",
    "                    else:\n",
    "                        n = dice[i] - 1\n",
    "                    temp_cd += [None] * n\n",
    "            else:\n",
    "                temp_cd += current_import_cd\n",
    "            \n",
    "            if not [x for x in current_export_cd if x]:\n",
    "                codes.append(current_code)\n",
    "            \n",
    "            # if l - len(temp_cd) < 0:\n",
    "            #     print(current_code, dice)\n",
    "            # temp_cd += [None] * (l - len(temp_cd))\n",
    "            import_cds += temp_cd\n",
    "\n",
    "            current_import = []\n",
    "            current_export = []\n",
    "            current_import_cd = []\n",
    "            current_export_cd = []\n",
    "\n",
    "            current_import_cd.append(row['CD IMPORT'])\n",
    "            current_export_cd.append(row['CD EXPORT'])\n",
    "            current_import.append(row['NVL QTY'])\n",
    "            current_export.append(row['TP QTY'])\n",
    "\n",
    "    current_code = row['NVL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.loc[~dfx['NVL'].isin(codes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.fillna(0, inplace=True)\n",
    "dfx.reset_index(inplace=True)\n",
    "del dfx['index']\n",
    "\n",
    "current_code = None\n",
    "\n",
    "current_import_cd = []\n",
    "current_export_cd = []\n",
    "\n",
    "current_import = []\n",
    "current_export = []\n",
    "\n",
    "nvl_names = []\n",
    "nvl_units = []\n",
    "import_cds = []\n",
    "import_dates = []\n",
    "import_qty = []\n",
    "tax_totals = []\n",
    "tax_rates = []\n",
    "\n",
    "\n",
    "export_cds = []\n",
    "export_dates = []\n",
    "export_qty = []\n",
    "tps = []\n",
    "tp_units = []\n",
    "tp_names = []\n",
    "bom_values = []\n",
    "\n",
    "to_delete = []\n",
    "\n",
    "\n",
    "for count, row in dfx.iterrows():\n",
    "    if not current_code:\n",
    "        current_import_cd.append(row['CD IMPORT'])\n",
    "        current_export_cd.append(row['CD EXPORT'])\n",
    "\n",
    "        current_import.append(row['NVL QTY'])\n",
    "        current_export.append(row['TP QTY'])\n",
    "\n",
    "    else:\n",
    "        if current_code == row['NVL']:\n",
    "            current_import_cd.append(row['CD IMPORT'])\n",
    "            current_export_cd.append(row['CD EXPORT'])\n",
    "            \n",
    "            current_import.append(row['NVL QTY'])\n",
    "            current_export.append(row['TP QTY'])\n",
    "        else:\n",
    "            # GET DICE FOR DEVIDE LIST\n",
    "            k = 0\n",
    "            im = 0\n",
    "            ex = 0\n",
    "            dice = [0]\n",
    "            \n",
    "            length = len(current_import)\n",
    "            im = current_import.pop(0)\n",
    "\n",
    "\n",
    "            for i in range(length):\n",
    "                ex += current_export[i]\n",
    "                if ex < im:\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        im += current_import.pop(0)\n",
    "                    except:\n",
    "                        pass\n",
    "                    dice.append(i)\n",
    "            # --------------------------\n",
    "            clean_import_cd = [x for x in current_import_cd if x]\n",
    "            temp_cd = []\n",
    "\n",
    "            for i in range(len(dice)):\n",
    "                try:\n",
    "                    temp_cd.append(clean_import_cd.pop(0))\n",
    "                except IndexError:\n",
    "                    break\n",
    "\n",
    "                if i < len(dice) - 1:\n",
    "                    temp_cd += [None] * (dice[i+1] - dice[i] - 1)\n",
    "\n",
    "\n",
    "            if len(temp_cd) < len(current_export):\n",
    "                temp_cd.append(None)\n",
    "            \n",
    "            to_delete += range(count-(len(current_export) - len(temp_cd)), count)\n",
    "            import_cds += temp_cd\n",
    "\n",
    "            current_import = []\n",
    "            current_export = []\n",
    "            current_import_cd = []\n",
    "            current_export_cd = []\n",
    "\n",
    "            current_import_cd.append(row['CD IMPORT'])\n",
    "            current_export_cd.append(row['CD EXPORT'])\n",
    "            current_import.append(row['NVL QTY'])\n",
    "            current_export.append(row['TP QTY'])\n",
    "\n",
    "            \n",
    "\n",
    "    current_code = row['NVL']\n",
    "\n",
    "\n",
    "\n",
    "dfy = dfx.drop(to_delete)\n",
    "dfy['CD IMPORT'] = import_cds\n",
    "dfy['CD EXPORT'] = export_cds\n",
    "dfy['NVL NAME'] = nvl_names\n",
    "dfy['NVL UNIT'] = nvl_units\n",
    "dfy['IMPORT_DATE'] = import_dates\n",
    "dfy['NVL QTY'] = import_qty\n",
    "dfy['Tổng trị giá'] = tax_totals\n",
    "dfy['Thuế suất XNK'] = tax_rates\n",
    "dfy['EXPORT_DATE'] = export_dates\n",
    "dfy['TP QTY'] = export_qty\n",
    "dfy['TP'] = tps\n",
    "dfy['TP UNIT'] = tp_units\n",
    "dfy['TP NAME'] = tp_names\n",
    "dfy['bom_value'] = bom_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../output/kok.xlsx', converters={'CD IMPORT': str, 'CD EXPORT': str})\n",
    "\n",
    "current_code = None\n",
    "current_import = []\n",
    "current_export = []\n",
    "current_import_cd = []\n",
    "current_nvl_names = []\n",
    "current_nvl_units = []\n",
    "current_import_cds = []\n",
    "current_import_dates = []\n",
    "current_import_qty = []\n",
    "current_tax_totals = []\n",
    "current_tax_rates = []\n",
    "\n",
    "\n",
    "nvl_names = []\n",
    "nvl_units = []\n",
    "import_cds = []\n",
    "import_dates = []\n",
    "import_qty = []\n",
    "tax_totals = []\n",
    "tax_rates = []\n",
    "\n",
    "\n",
    "export_cds = []\n",
    "export_dates = []\n",
    "export_qty = []\n",
    "tps = []\n",
    "tp_units = []\n",
    "tp_names = []\n",
    "bom_values = []\n",
    "\n",
    "to_delete = []\n",
    "\n",
    "\n",
    "for count, row in df.iterrows():\n",
    "    if not current_code:\n",
    "        current_import_cd.append(row['CD IMPORT'])\n",
    "        current_import.append(row['NVL QTY'])\n",
    "        current_export.append(row['TP QTY'])\n",
    "        current_nvl_names.append(row['NVL NAME'])\n",
    "        current_nvl_units.append(row['NVL UNIT'])\n",
    "        current_import_dates.append(row['IMPORT_DATE'])\n",
    "        current_import_qty.append(row['NVL QTY'])\n",
    "        current_tax_totals.append(row['Tổng trị giá'])\n",
    "        current_tax_rates.append(row['Thuế suất XNK'])\n",
    "\n",
    "    else:\n",
    "        if current_code == row['NVL']:\n",
    "            current_import_cd.append(row['CD IMPORT'])\n",
    "            current_import.append(row['NVL QTY'])\n",
    "            current_export.append(row['TP QTY'])\n",
    "            current_nvl_names.append(row['NVL NAME'])\n",
    "            current_nvl_units.append(row['NVL UNIT'])\n",
    "            current_import_dates.append(row['IMPORT_DATE'])\n",
    "            current_import_qty.append(row['NVL QTY'])\n",
    "            current_tax_totals.append(row['Tổng trị giá'])\n",
    "            current_tax_rates.append(row['Thuế suất XNK'])\n",
    "\n",
    "        else:\n",
    "            # GET DICE FOR DEVIDE LIST\n",
    "            k = 0\n",
    "            im = 0\n",
    "            ex = 0\n",
    "            dice = [0]\n",
    "            \n",
    "            length = len(current_import)\n",
    "            im = current_import.pop(0)\n",
    "\n",
    "            for i in range(length):\n",
    "                ex += current_export[i]\n",
    "                if ex < im:\n",
    "                    pass\n",
    "                else:\n",
    "                    \n",
    "                    try:\n",
    "                        im += current_import.pop(0)\n",
    "                        dice.append(i)\n",
    "                    except:\n",
    "                        dice.append(i-1)\n",
    "                    \n",
    "            # --------------------------\n",
    "            clean_import_cd = [x for x in current_import_cd if x]\n",
    "            clean_nvl_names = [x for x in current_nvl_names if x]\n",
    "            clean_nvl_units = [x for x in current_nvl_units if x]\n",
    "            clean_import_dates = [x for x in current_import_dates if x]\n",
    "            clean_import_qty = [x for x in current_import_qty if x]\n",
    "            clean_tax_totals = [x for x in current_tax_totals if x]\n",
    "            clean_tax_rates = [x for x in current_tax_rates if x]\n",
    "\n",
    "            temp_cd = []\n",
    "            temp_nvl_names = []\n",
    "            temp_nvl_units = []\n",
    "            temp_import_dates = []\n",
    "            temp_import_qty = []\n",
    "            temp_tax_totals = []\n",
    "            temp_tax_rates = []\n",
    "\n",
    "\n",
    "            for i in range(len(dice)):\n",
    "                try:\n",
    "                    temp_cd.append(clean_import_cd.pop(0))\n",
    "                    temp_nvl_names.append(current_nvl_names.pop(0))\n",
    "                    temp_nvl_units.append(current_nvl_units.pop(0))\n",
    "                    temp_import_dates.append(current_import_dates.pop(0))\n",
    "                    temp_import_qty.append(current_import_qty.pop(0))\n",
    "                    temp_tax_totals.append(current_tax_totals.pop(0))\n",
    "                    temp_tax_rates.append(current_tax_rates.pop(0))\n",
    "                except IndexError:\n",
    "                    break\n",
    "\n",
    "                if i < len(dice) - 1:\n",
    "                    temp_cd += [None] * (dice[i+1] - dice[i] - 1)\n",
    "                    temp_nvl_names += [None] * (dice[i+1] - dice[i] - 1)\n",
    "                    temp_nvl_units += [None] * (dice[i+1] - dice[i] - 1)\n",
    "                    temp_import_dates += [None] * (dice[i+1] - dice[i] - 1)\n",
    "                    temp_import_qty += [None] * (dice[i+1] - dice[i] - 1)\n",
    "                    temp_tax_totals += [None] * (dice[i+1] - dice[i] - 1)\n",
    "                    temp_tax_rates += [None] * (dice[i+1] - dice[i] - 1)\n",
    "\n",
    "\n",
    "            if len(temp_cd) < len(current_export):\n",
    "                temp_cd.append(None)\n",
    "                temp_nvl_names.append(None)\n",
    "                temp_nvl_units.append(None)\n",
    "                temp_import_dates.append(None)\n",
    "                temp_import_qty.append(None)\n",
    "                temp_tax_totals.append(None)\n",
    "                temp_tax_rates.append(None)\n",
    "            \n",
    "            to_delete += range(count-(len(current_export) - len(temp_cd)), count)\n",
    "            import_cds += temp_cd\n",
    "            nvl_names += temp_nvl_names\n",
    "            nvl_units += temp_nvl_units\n",
    "            import_dates += temp_import_dates\n",
    "            import_qty += temp_import_qty\n",
    "            tax_totals += temp_tax_totals\n",
    "            tax_rates += temp_tax_rates\n",
    "\n",
    "\n",
    "            current_import = []\n",
    "            current_export = []\n",
    "            current_import_cd = []\n",
    "            current_nvl_names = []\n",
    "            current_nvl_units = []\n",
    "            current_import_cds = []\n",
    "            current_import_dates = []\n",
    "            current_import_qty = []\n",
    "            current_tax_totals = []\n",
    "            current_tax_rates = []\n",
    "\n",
    "\n",
    "            current_import_cd.append(row['CD IMPORT'])\n",
    "            current_import.append(row['NVL QTY'])\n",
    "            current_export.append(row['TP QTY'])\n",
    "            current_nvl_names.append(row['NVL NAME'])\n",
    "            current_nvl_units.append(row['NVL UNIT'])\n",
    "            current_import_dates.append(row['IMPORT_DATE'])\n",
    "            current_import_qty.append(row['NVL QTY'])\n",
    "            current_tax_totals.append(row['Tổng trị giá'])\n",
    "            current_tax_rates.append(row['Thuế suất XNK'])\n",
    "\n",
    "\n",
    "    current_code = row['NVL']\n",
    "\n",
    "import_cds.pop()\n",
    "nvl_names.pop()\n",
    "nvl_units.pop()\n",
    "import_dates.pop()\n",
    "import_qty.pop()\n",
    "tax_totals.pop()\n",
    "tax_rates.pop()\n",
    "\n",
    "df['CD IMPORT'] = import_cds\n",
    "df['NVL NAME'] = nvl_names\n",
    "df['NVL UNIT'] = nvl_units\n",
    "df['IMPORT_DATE'] = import_dates\n",
    "df['NVL QTY'] = import_qty\n",
    "df['Tổng trị giá'] = tax_totals\n",
    "df['Thuế suất XNK'] = tax_rates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../output/res.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "'NVL', 'NVL NAME', 'NVL UNIT', 'IMPORT_DATE', 'CD IMPORT', 'CD EXPORT',\n",
    "'NVL QTY', 'TP QTY', 'TPxBOM', 'TP', 'TP NAME', 'TP UNIT', 'bom_value',\n",
    "'Tổng trị giá', 'Thuế suất XNK', 'EXPORT_DATE'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0171f5b0cde5d5b5cb625450b6c85a97936af2366b7d63a942c5e5929a1ed776"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
